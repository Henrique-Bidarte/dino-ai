{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mss pydirectinput pytesseract tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box, Discrete\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3 import DQN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ACTION = 'space'\n",
    "DOWN_ACTION = 'down'\n",
    "NO_OP_ACTION = 'no_op'\n",
    "GAME_OVER_POSSIBLE_STRING_DETECTIONS = ['GAME', 'GAHE']\n",
    "\n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'\n",
    "CALLBACK_CHECK_FREQ = 10000\n",
    "VERBOSE = 1\n",
    "\n",
    "DQN_POLICY = 'CnnPolicy'\n",
    "DQN_BUFFER_SIZE = 20000\n",
    "DQN_LEARNING_STARTS = 1000\n",
    "DQN_TOTAL_TIMESTEPS = 200000\n",
    "DQN_BEST_MODEL_PATH = 'best_model.zip'\n",
    "DQN_LOAD_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoGame(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,100), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 300, 'left': 0, 'width': 600, 'height': 500}\n",
    "        self.game_over_location = {'top': 405, 'left': 630, 'width': 660, 'height': 70}\n",
    "\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0: SPACE_ACTION,\n",
    "            1: DOWN_ACTION,\n",
    "            2: GAME_OVER_POSSIBLE_STRING_DETECTIONS\n",
    "        }\n",
    "\n",
    "        if action != 2:\n",
    "            pydirectinput.press(action_map[action])\n",
    "        \n",
    "        game_over = self.get_game_over()\n",
    "        new_observation = self.get_observation()\n",
    "\n",
    "        reward = 1\n",
    "        truncated = None\n",
    "        info = {}\n",
    "\n",
    "        return new_observation, reward, game_over, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        cv2.imshow(\"Game\", np.array(self.cap.grab(self.game_location)))[:,:,:3]\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close_observation\n",
    "\n",
    "    def close_observation(self):\n",
    "        cv2.destroyAllWindows()\n",
    "  \n",
    "    def reset(self, seed=None):\n",
    "        time.sleep(2)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation(), seed\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (100,83))\n",
    "        channel = np.reshape(resized, (1,83,100))\n",
    "        \n",
    "        return channel\n",
    "        \n",
    "    def get_game_over(self):\n",
    "        game_over_cap = np.array(self.cap.grab(self.game_over_location))[:,:,:3]\n",
    "        \n",
    "        game_over = False\n",
    "\n",
    "        string_detection = pytesseract.image_to_string(game_over_cap)[:4]\n",
    "        if string_detection in GAME_OVER_POSSIBLE_STRING_DETECTIONS:\n",
    "            game_over = True\n",
    "\n",
    "        return game_over\n",
    "\n",
    "env = DinoGame()\n",
    "\n",
    "obs = env.get_observation()\n",
    "plt.imshow(obs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=VERBOSE):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "    \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=CALLBACK_CHECK_FREQ, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "if DQN_LOAD_MODEL is True:\n",
    "    model = DQN.load(DQN_BEST_MODEL_PATH, env=env)\n",
    "     \n",
    "else:\n",
    "    model = DQN(DQN_POLICY, env, tensorboard_log = LOG_DIR, verbose=VERBOSE, buffer_size=DQN_BUFFER_SIZE, learning_starts=DQN_LEARNING_STARTS)\n",
    "\n",
    "model.learn(total_timesteps=DQN_TOTAL_TIMESTEPS, callback=callback) \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
